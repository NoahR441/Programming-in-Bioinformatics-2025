{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning reads & processing SAM files\n",
    "\n",
    "Exercise for creating and processing short read alignments.\n",
    "\n",
    "* **Contact:** mate.balajti@unibas.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General\n",
    "\n",
    "Be sure to nicely format your answer.\n",
    "Indicate your name in the file name!\n",
    "_Ex2_solutions_Name_LastName.py_ would be a good approach to this.\n",
    "Document, report and detail your work, make sure we can follow and execute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Operating system\n",
    "\n",
    "For solving these exercises, you need to work in Bash on a Unix-type terminal,\n",
    "so if you are behind either a Linux distribution, a Mac or a BSD system etc.,\n",
    "you ​ should ​ be good to go. If instead you only have access to a Windows 10/11\n",
    "computer, you should be able to make use of the support the system offers for\n",
    "Linux/Ubuntu through their cooperation with Canonical. \n",
    "\n",
    "If you have experience with Docker, one other possible option is to\n",
    "use a Docker image that contains all required software. For example, starting\n",
    "from a Linux image (e.g., latest Ubuntu), which provides Linux/GNU/Bash out of\n",
    "the box, you could install STAR and/or any other required Linux software by\n",
    "writing an appropriate Dockerfile and then building that image. You can also\n",
    "search online for available images that already contain these tools (e.g.,\n",
    "[this](https://hub.docker.com/r/mgibio/star​) looks like one you\n",
    "could use for running STAR; see below). If you decide to go this route, be\n",
    "aware that Docker on Windows still runs in a VM and support is not always\n",
    "stable.\n",
    "\n",
    "> **Note:** If you are planning to do more bioinformatics work in the future,\n",
    "> it is definitely a good idea to have a stable Linux system at hand at all\n",
    "> times. In this case, you might want to consider installing a Linux\n",
    "> distribution side-by-side with your Windows OS (search for “Linux Windows\n",
    "> dual boot” or similar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software\n",
    "\n",
    "In the last exercise, you were asked to write a simple, naive short read\n",
    "aligner from scratch. While this is a good exercise, it is not suitable for\n",
    "actual analysis, because your code won’t be optimized to handle the amounts of\n",
    "data that next-generation sequencing typically yields. Since the dawn of\n",
    "high-throughput sequencing techniques in the mid 2000’s, a lot of effort has\n",
    "been put into designing and implementing very efficient methods at mapping\n",
    "short reads to reference sequences. For this exercise, we will use a popular\n",
    "option called [STAR](https://github.com/alexdobin/STAR). Among many other\n",
    "features, STAR supports spliced alignments and optionally accepts gene\n",
    "annotations in GTF format next to a genome reference to increase the fidelity\n",
    "of mapping reads that cover splice junctions (if not provided, STAR, by\n",
    "default, will try to infer splice junctions from the genome reference and the\n",
    "reads). Please either install STAR (and any other third-party software you\n",
    "need) via the [Conda](https://docs.conda.io/en/latest/miniconda.html) package\n",
    "manager _OR_ use Docker containers as suggested above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation for Windows\n",
    "\n",
    "_STAR_ is only available as Docker image on Windows.\n",
    "Here we assume Docker is not yet installed and Windows 10 or 11 is used.\n",
    "Coarse installation steps:\n",
    "* Install WSL2 (Windows subsystem for Linux) backend\n",
    "  https://learn.microsoft.com/en-us/windows/wsl/install\n",
    "* Install Docker https://docs.docker.com/desktop/install/windows-install/\n",
    "* Ensure the installation was successful by following the _Quick Start Guide_.\n",
    "* Get the STAR docker image by executing the following command in\n",
    "a PowerShell or Windows Command Prompt window (in Linux it is called a terminal window).\n",
    "  ```bash\n",
    "  docker pull mgibio/star\n",
    "  ```\n",
    "\n",
    "> Note: please refer to the most up-to-date documentation\n",
    "> by checking the online instructions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a Docker image\n",
    "\n",
    "To have the local files visible in the container, one needs to mount the directory onto the host (in this case the STAR container). \n",
    "\n",
    "For example, to mount `C:\\paths\\to\\test_files` (absolute path to directory `test_files`) onto `/docker_main/files` (the path and name of the directory on the Linux-based host):\n",
    "```bash\n",
    "docker run -it \\\n",
    "  --mount type=bind,source=\"C:\\paths\\to\\test_files\",target=/docker_main/files \\\n",
    "  mgibio/star:latest\n",
    "```\n",
    "\n",
    "> Note: on Linux, paths are constructed with slash \"/\", whereas on Windows with backslash \"\\\\\"!\n",
    "\n",
    "> Note: to get help about the command `docker run`,\n",
    "> try running `docker run --help`\n",
    "> or search online for the command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1: Create index (1 points)\n",
    "\n",
    "Follow [STAR’s manual](https://physiology.med.cornell.edu/faculty/skrabanek/lab/angsd/lecture_notes/STARmanual.pdf#page=4) to create an index of the provided genome ​`FASTA`​ file\n",
    "and ​`GTF`​ gene annotations. Note that to allow the mapping to be done on a\n",
    "laptop, only chromosome 19 and the corresponding gene annotations are provided.\n",
    "In a typical setting, indexing and mapping would be done on all chromosomes and\n",
    "an unfiltered set of annotations. Note also that files are provided in a\n",
    "compressed form (`GZIP`) for easy sharing and may need to be uncompressed\n",
    "before use (check the instructions whether passing `GZIP`ped files directly is\n",
    "accepted).\n",
    "\n",
    "Required files:\n",
    "\n",
    "* Genome:​ `Mus_musculus.GRCm38.dna_rm.chr19.fa.gz`\n",
    "* Gene annotations: `Mus_musculus.GRCm38.88.chr19.gtf.gz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3320603014.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mSTAR --runThreadN 4      --runMode genomeGenerate      --genomeDir STAR_index_chr19      --genomeFastaFiles Mus_musculus.GRCm38.dna_rm.chr19.fa      --sjdbGTFfile Mus_musculus.GRCm38.88.chr19.gtf      --sjdbOverhang 99      --genomeSAindexNbases 11\u001b[39m\n                      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Copy your indexing command here\n",
    "STAR \n",
    "--runThreadN 4      \n",
    "--runMode genomeGenerate      \n",
    "--genomeDir STAR_index_chr19      \n",
    "--genomeFastaFiles Mus_musculus.GRCm38.dna_rm.chr19.fa      \n",
    "--sjdbGTFfile Mus_musculus.GRCm38.88.chr19.gtf      \n",
    "--sjdbOverhang 99      \n",
    "--genomeSAindexNbases 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2: Align reads (1 points)\n",
    "\n",
    "Follow STAR’s manual to align reads to the reference, using the index you have\n",
    "created in exercise 2.1. Note that we are dealing here with (part of) a\n",
    "__paired-end sequencing library__, so you will need to provide both read library\n",
    "files for this step.\n",
    "\n",
    "ATTENTION: The running of the mapping may take quite some time if you're working on your local machine. (up to 10-15min)\n",
    "\n",
    "Required files:\n",
    "\n",
    "* Control mate 1: `control.mate_1.fq.gz`\n",
    "* Control mate 2: `control.mate_2.fq.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1593967555.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m--runThreadN 4 \\\u001b[39m\n                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Copy your alignment command here\n",
    "        STAR \n",
    "--runThreadN 4 \n",
    "--genomeDir STAR_index_chr19 \n",
    "--readFilesIn control.mate_1.fq.gz control.mate_2.fq.gz \n",
    "--readFilesCommand zcat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Process alignments\n",
    "\n",
    "#### Exercise 2.3: Process alignments (2 points)\n",
    "\n",
    "Working with SAM/BAM files using SAMtools\n",
    "\n",
    "After STAR produces the alignments, the results are written by default in **SAM** format (Sequence Alignment/Map). SAM is a plain text file that can get very large and slow to work with. For efficient storage and processing, SAM files are usually converted into BAM format (the binary, compressed equivalent).\n",
    "\n",
    "To process BAM files further (for example, to feed them into downstream analysis tools), they also need to be sorted (by genomic coordinate) and indexed (to allow rapid retrieval of reads overlapping specific regions).\n",
    "\n",
    "This is where [SAMtools](https://www.htslib.org/) comes in. SAMtools is a widely used toolkit for manipulating SAM and BAM files.\n",
    "\n",
    "**Installing SAMtools**\n",
    "\n",
    "If you are working in a conda environment, you can install SAMtools with:\n",
    "\n",
    "```bash\n",
    "conda install -c bioconda samtools\n",
    "```\n",
    "\n",
    "Look up how to:\n",
    "1. Convert the SAM files produced by STAR into BAM format.\n",
    "2. Sort the BAM files by genomic coordinate.\n",
    "3. Index the sorted BAM files to generate `.bai` index files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your commands here\n",
    "installed samtools\n",
    "\n",
    "samtools view -S -b Aligned.out.sam > control.aligned.bam\n",
    "samtools sort control.aligned.bam -o control.sorted.bam\n",
    "samtools index control.sorted.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.4: Count reads (2 points)\n",
    "\n",
    "Find out from the STAR output (Log.out or `SAM` files):\n",
    "\n",
    "* How many alignments were reported?\n",
    "* How many reads were uniquely mapped?  \n",
    "  **Hint:** check for the `NH` (number of hits) SAM tag\n",
    "* How many reads were mapped to multiple loci?\n",
    "* How many reads could not be mapped?\n",
    "\n",
    "Compare the sum of uniquely mapped, multi-mapped and unmapped reads to the\n",
    "total number of reads in the ​ FASTQ​ input files. Do the numbers match?\n",
    "\n",
    "> **Note:** See the [SAM​\n",
    "> specification](https://samtools.github.io/hts-specs/SAMv1.pdf) for more info\n",
    "> on SAM files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mMapping speed, Million of reads per hour |       16.21\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Write your answers here\n",
    "cat Log.final.out\n",
    "\n",
    " Started job on |       Sep 26 11:35:05\n",
    "                             Started mapping on |       Sep 26 11:35:06\n",
    "                                    Finished on |       Sep 26 11:36:45\n",
    "       Mapping speed, Million of reads per hour |       16.21\n",
    "\n",
    "                          Number of input reads |       445798\n",
    "                      Average input read length |       282\n",
    "                                    UNIQUE READS:\n",
    "                   Uniquely mapped reads number |       393774\n",
    "                        Uniquely mapped reads % |       88.33%\n",
    "                          Average mapped length |       280.29\n",
    "                       Number of splices: Total |       344155\n",
    "            Number of splices: Annotated (sjdb) |       336777\n",
    "                       Number of splices: GT/AG |       338130\n",
    "                       Number of splices: GC/AG |       2558\n",
    "                       Number of splices: AT/AC |       764\n",
    "               Number of splices: Non-canonical |       2703\n",
    "                      Mismatch rate per base, % |       0.59%\n",
    "                         Deletion rate per base |       0.01%\n",
    "                        Deletion average length |       1.55\n",
    "                        Insertion rate per base |       0.00%\n",
    "                       Insertion average length |       1.35\n",
    "                             MULTI-MAPPING READS:\n",
    "        Number of reads mapped to multiple loci |       3917\n",
    "             % of reads mapped to multiple loci |       0.88%\n",
    "        Number of reads mapped to too many loci |       36\n",
    "             % of reads mapped to too many loci |       0.01%\n",
    "                                  UNMAPPED READS:\n",
    "  Number of reads unmapped: too many mismatches |       0\n",
    "       % of reads unmapped: too many mismatches |       0.00%\n",
    "            Number of reads unmapped: too short |       48071\n",
    "                 % of reads unmapped: too short |       10.78%\n",
    "                Number of reads unmapped: other |       0\n",
    "                     % of reads unmapped: other |       0.00%\n",
    "                                  CHIMERIC READS:\n",
    "                       Number of chimeric reads |       0\n",
    "                            % of chimeric reads |       0.00%\n",
    "\n",
    "445798 total\n",
    "393774 unique\n",
    "3917 multimapped\n",
    "48107 reads could not be mapped\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.5: Run custom functions on STAR results (4 points)\n",
    "\n",
    "`FASTQ`​ (for reads), ​`FASTA`​ (for reference sequences and reads if sequencing\n",
    "quality scores are disregarded or discarded), ​`GTF`​/`GFF`​ (for gene\n",
    "annotations/features), `SAM` (for alignments; with the corresponding\n",
    "binary/compressed versions ​`BAM`,​ and, more recently, ​`CRAM​`), ​`BED​` (generic\n",
    "tabular format for representing genomic ranges) are the main file types that\n",
    "are used in the analysis of RNA-Seq data. Relevant tools in the field will\n",
    "nowadays almost always require input files and report their own outputs in any\n",
    "of these formats. However, not every tool accepting a `FASTA`​ file as input\n",
    "will also accept a ​`FASTQ`​ file, although it is trivial to convert ​`FASTQ​` to\n",
    "`FASTA` in a non-lossy way. In addition, both for legacy and new tools, custom\n",
    "formats are still being used, occasionally, to represent specialized\n",
    "information. Therefore, writing and applying parsers and converters to convert\n",
    "outputs of one tool such that they can be used as inputs to another is a\n",
    "somewhat menial, but common task that bioinformaticians are often faced with.\n",
    "\n",
    "To practice this and connect to the work you have done in the previous exercise:\n",
    "\n",
    "* Write code that converts a ​`SAM​` file to a ​`FASTA`​ file and apply it on the\n",
    "  output of exercise 2.2 (align reads). If you didn’t manage to solve exercise 2.2, write\n",
    "  code that converts ​`FASTQ`​ to ​`FASTA` instead.\n",
    "* Convert your files to ​`FASTA`​ and then apply your functions (`parse_fasta()`, `discard_ambiguous_seqs()` and `map_reads()`) from the previous session to the output (Exercise_1).\n",
    "  * Note: `map_reads()` will likely not finish in reasonable time.\n",
    "    Thus, it is fine to stop it. But report and reason about why this could be the case. What makes the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert SAM to FASTA\n",
    "def sam_to_fasta(sam_file, fasta_file):\n",
    "     with open(sam_file, 'r') as sam_in, open(fasta_file, 'w') as fasta_out:\n",
    "        for line in sam_in:\n",
    "            if line.startswith('@'):\n",
    "                continue\n",
    "            \n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 10:\n",
    "                continue\n",
    "                \n",
    "            read_id = fields[0]\n",
    "            sequence = fields[9]\n",
    "            \n",
    "            # Write in FASTA format\n",
    "            fasta_out.write(f'>{read_id}\\n{sequence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sam_file=\"Aligned.out.sam\"\n",
    "fasta_file = \"Aligned.out.fasta\"\n",
    "\n",
    "sam_to_fasta(sam_file, fasta_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta(path: str) -> tuple[list[str], list[str]]:\n",
    "    header = []\n",
    "    sequence = []\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                current_header= line[1:].strip()\n",
    "                header.append(current_header)\n",
    "            else:\n",
    "                sequence.append(line)\n",
    "\n",
    "    return header, sequence\n",
    "def discard_ambiguous_seqs(header: list[str], sequence: list[str]) -> \\\n",
    "  tuple[: list[str], : list[str]]:\n",
    "    r_header = []\n",
    "    r_sequence = []\n",
    "    r_char= set('ACGTacgt')\n",
    "    for i, seq in enumerate(sequence):\n",
    "        if all(char in r_char for char in seq):\n",
    "            r_sequence.append(seq)\n",
    "            r_header.append(header[i])\n",
    "            \n",
    "    return r_header, r_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, sequence = parse_fasta(fasta_file)\n",
    "r_header, r_sequence = discard_ambiguous_seqs(header, sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** As an alternative to alignment- and count-based approaches to a\n",
    "> differential gene expression, nowadays probabilistic methods are increasingly\n",
    "> being used for similar purposes.  These have several advantages, such as\n",
    "> (typically) requiring fewer steps and less compute resources. Importantly,\n",
    "> they provide abundances for individual transcripts and thus enable analyses,\n",
    "> such as differential transcript expression and isoform usage analysis, which\n",
    "> the count-based methods do not readily allow. A downside for these methods is\n",
    "> that they are not easy to understand in detail, making results harder to\n",
    "> interpret and potentially more sensitive to biases. The two main tools for\n",
    "> alignment-free estimation of transcript abundances are\n",
    "> [Salmon](​https://github.com/COMBINE-lab/salmon) and\n",
    "> [kallisto](https://github.com/pachterlab/kallisto​)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
